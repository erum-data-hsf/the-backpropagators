Search.setIndex({"alltitles": {"Activation Function Practice": [[3, null]], "Activation Functions": [[0, null]], "Definition": [[0, "definition"]], "ELU: Exponential Linear Unit": [[0, "elu-exponential-linear-unit"]], "Exercise 1:": [[3, "exercise-1"]], "Exercise 2:": [[3, "exercise-2"]], "Exercise 3:": [[3, "exercise-3"]], "Leaky ReLU": [[3, "leaky-relu"]], "Mathematical Foundation": [[2, null]], "Mish": [[0, "mish"]], "ReLU (Rectified Linear Unit)": [[3, "relu-rectified-linear-unit"]], "SELU: Scaled Exponential Linear Unit": [[0, "selu-scaled-exponential-linear-unit"]], "Softmax": [[0, "softmax"], [3, "softmax"]], "Use": [[0, "use"]], "Welcome to our book on Activation Functions": [[1, null]], "relu": [[0, "relu"]], "sigmoid": [[0, "sigmoid"]], "step_function": [[0, "step-function"]], "tanh": [[0, "tanh"]]}, "docnames": ["activation_functions", "intro", "mathematical_foundations", "practical_implementations"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["activation_functions.md", "intro.md", "mathematical_foundations.md", "practical_implementations.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 3], "0": [0, 3], "01": 3, "05083836": 0, "0x14ca9fd60": [], "0x15529fd60": [], "0x15939fd60": 3, "0x168a9bd60": [], "0x176647fa0": [], "1": [0, 1], "10": [0, 3], "100": 0, "11314284": 0, "12": 3, "19680801": [], "2": [0, 1], "3": [0, 1], "4": [0, 3], "400": 3, "5": 3, "6": 0, "8360188": 0, "As": [], "But": 0, "By": 3, "For": [], "In": 0, "It": 3, "No": [], "The": [0, 3], "There": [], "_": 0, "about": [], "activ": [], "add_": [], "advanc": 0, "align": [], "all": [0, 3], "allow": 3, "alpha": [0, 3], "also": [], "an": [0, 3], "appli": 0, "arrai": 3, "attribut": 0, "automat": 0, "ax": 3, "axhlin": 3, "becaus": [0, 3], "becom": 3, "befor": 0, "begin": 3, "behavior": 0, "benefit": 0, "big": 0, "black": 3, "blue": 3, "book": [], "built": 3, "bundl": 1, "call": [], "can": [], "care": 0, "case": 3, "cell": 0, "check": 1, "class": [0, 3], "classif": [0, 3], "cm": [], "cmap": [], "code": 3, "cold": [], "color": 3, "commonli": 3, "compar": 3, "connect": 0, "constant": 3, "content": 1, "converg": 3, "convert": [0, 3], "coolwarm": [], "creat": [], "curv": 3, "custom_lin": [], "cycler": [], "data": [], "deep": 3, "deeper": 3, "def": [0, 3], "defin": 3, "dens": 0, "deriv": 0, "design": 3, "directli": 3, "displaystyl": 0, "disrupt": 0, "distribut": 0, "divid": 0, "do": [], "document": [], "dollar": [], "drawback": 0, "dropout": 0, "dy": 3, "e": [0, 3], "e_x": 0, "each": [0, 3], "effect": 3, "element": [0, 3], "emb": [], "end": 3, "escap": [], "etc": [], "exampl": [], "exclus": 0, "exercis": 1, "exhibit": 0, "exp": [0, 3], "f": 0, "faster": 3, "fig": 3, "figsiz": 3, "figur": 0, "first": 0, "fix": [], "foundat": 1, "frac": 3, "from": 3, "fucntion": [], "fulli": 0, "gain": 3, "geq": 3, "gradient": 3, "green": 3, "guid": [], "hand": 3, "help": [0, 3], "here": 3, "hot": [], "html": [], "i": [0, 3], "ii": [], "imag": [], "implement": 3, "import": [0, 3], "inact": 3, "includ": [], "inform": [], "initi": 0, "input": [0, 3], "interact": [], "invalid": 0, "ion": [], "its": 0, "j": [0, 3], "jupyt": [], "k": 0, "keep": 0, "l": 3, "la_": [], "label": 3, "lambda": 0, "last": [], "layer": [0, 3], "leaki": 0, "leaky_relu": 3, "leaky_relu_lay": 3, "leakyrelu": 3, "learn": [0, 3], "legend": 3, "librari": 3, "likelihood": 3, "line": 0, "line2d": [], "linewidth": 3, "linspac": [0, 3], "ln": 0, "logit": 3, "logspac": [], "lot": [], "lw": [], "mainli": 0, "make": 3, "math": [], "mathemat": 1, "matplotlib": [0, 3], "max": 0, "maximum": 3, "mbox": [], "mean": [], "mechan": 3, "medium": [], "model": 3, "modul": [], "modulenotfounderror": [], "more": 1, "most": [], "multi": [0, 3], "must": 0, "n": [], "name": [], "necessari": 3, "neg": 3, "negative_slop": 3, "network": 0, "neuron": 3, "nn": 3, "non": 3, "normal": 0, "notebook": 3, "np": [0, 3], "number": [0, 3], "numpi": [0, 3], "onli": 3, "otherwis": 3, "out": 1, "output": [0, 3], "page": 1, "plot": [0, 3], "plt": [0, 3], "posit": 3, "post": [], "practic": 1, "present": 3, "prevent": 3, "print": 0, "probabl": [0, 3], "problem": [0, 3], "process": 0, "prop_cycl": [], "pyplot": [0, 3], "python": 3, "pytorch": 3, "randn": [], "random": [], "rang": 3, "raw": 3, "rcparam": [], "real": 0, "recent": [], "recogn": 0, "reduc": 3, "regular": 0, "relu_lay": 3, "reproduc": [], "requir": 0, "result": 3, "return": [0, 3], "sampl": [1, 3], "score": [0, 3], "scratch": 3, "see": 1, "seed": [], "self": 0, "set_titl": 3, "set_xlabel": 3, "set_ylabel": 3, "shortcom": 0, "show": [0, 3], "sigma": 0, "sigmoid": 3, "sigmoid_lay": 3, "sign": [], "small": 3, "some": [], "special": 0, "stabil": 0, "standard": 0, "state": [], "subplot": 3, "suitabl": 3, "sum": [0, 3], "sum_": [0, 3], "sure": [], "syntax": 0, "syntaxerror": 0, "t": [], "take": 3, "task": 3, "term": 0, "test": 3, "tex": [], "text": 3, "th": 3, "thi": [1, 3], "thu": 0, "torch": 3, "traceback": [], "tupl": 0, "understand": [0, 3], "us": 3, "usag": [], "valu": [0, 3], "vanish": 3, "variant": 3, "variou": 3, "vector": 3, "version": 0, "want": [], "weight": 0, "well": [], "when": 3, "where": 3, "wide": 3, "work": 0, "write": 3, "written": 3, "x": [0, 3], "x_i": 3, "x_j": 3, "x_torch": 3, "y": [0, 3], "y_torch": 3, "you": 3, "your": 3, "z": 0, "z_": 0, "zero": 3, "\u624b\u5199relu": []}, "titles": ["Activation Functions", "Welcome to our book on Activation Functions", "Mathematical Foundation", "Activation Function Practice"], "titleterms": {"1": 3, "2": 3, "3": 3, "activ": [0, 1, 3], "block": [], "book": 1, "code": [], "content": [], "definit": 0, "elu": 0, "exercis": 3, "exponenti": 0, "foundat": 2, "fucntion": [], "function": [0, 1, 3], "implement": [], "leaki": 3, "linear": [0, 3], "markdown": [], "mathemat": 2, "mish": 0, "myst": [], "notebook": [], "our": 1, "output": [], "practic": 3, "rectifi": 3, "relu": [0, 3], "scale": 0, "selu": 0, "sigmoid": 0, "softmax": [0, 3], "step_funct": 0, "tanh": 0, "unit": [0, 3], "us": 0, "welcom": 1}})